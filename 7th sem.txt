##FIBONACCI CODE

def fibo_eterative(num):
    stepCount = 2
    if num <= 1:
        return num
    else:
        a ,b =0, 1
        for i in range(1,num):
            stepCount+=1
            c = a+b
            a = b
            b = c
        print("Step count = ",stepCount)
        return b



def fibo_recursive(num):
    
    if(num<=1):
        return num
    else :
        return fibo_recursive(num-1) + fibo_recursive(num-2)

n = 15      
print(n,"th fibonaci number using eterative method is",fibo_eterative(n))
print(n,"th fibonaci number using recursive method is",fibo_recursive(n))


##############################################################################


##Fractional Knapsack

def knapSackProb(m, p, w):
    ratio = []
    dict1 = {}
    current_wt = m
    max_profit = 0
    for i in range(len(p)):
        ratio.append(p[i]/w[i])
        dict1[p[i]/w[i]] = {'profit': p[i], 'weight': w[i]}
        print(dict1)
    ratio.sort()
    ratio.reverse()
    for i in range(len(p)):
        if current_wt == 0:
            break
        if dict1[ratio[i]]['weight'] <= current_wt:
            max_profit += dict1[ratio[i]]['profit']
            current_wt -= dict1[ratio[i]]['weight']
        else:
            fraction = current_wt/dict1[ratio[i]]['weight']
            max_profit += fraction * dict1[ratio[i]]['profit']
            current_wt -= fraction * dict1[ratio[i]]['weight']
    print(dict1)
    return max_profit


m = int(input("Enter max weight"))
w = list(map(int, input("Enter values of weight").split()))
p = list(map(int, input("Enter values of profit").split()))

print(knapSackProb(m, p, w))



####################################################################



##program to solve a 0-1 Knapsack problem using dynamic programming or 
branch and bound strategy.


# A naive recursive implementation
# of 0-1 Knapsack Problem

# Returns the maximum value that
# can be put in a knapsack of
# capacity W

def knapSack(W, wt, val, n):
    # Base Case
    if n == 0 or W == 0:
        return 0

    # If weight of the nth item is
    # more than Knapsack of capacity W,
    # then this item cannot be included
    # in the optimal solution
    if (wt[n - 1] > W):
        return knapSack(W, wt, val, n - 1)

    # return the maximum of two cases:
    # (1) nth item included
    # (2) not included
    else:
        return max(
            val[n - 1] + knapSack(
                W - wt[n - 1], wt, val, n - 1),
            knapSack(W, wt, val, n - 1))

# end of function knapSack

# Driver Code
val = [60, 100, 120]
wt = [10, 20, 30]
W = 50
n = len(val)
print(knapSack(W, wt, val, n))




###########################################################################




##first Queen placed. Use backtracking to place 
remaining Queens to generate the final n-queenâ€—s matrix

global N
N = 4
cols = set([i for i in range(N)])

def printSolution(board):
    for i in range(N):
        for j in range(N):
            print(board[i][j], end=" ")
        print()
def isSafe(board, row, col):
    for i in range(col):
        if board[row][i] == 1:
            return False
    i, j = row - 1, col + 1
    while i >= 0 and j < N:
        if board[i][j] == 1:
            return False
        i -= 1
        j += 1

    i, j = row + 1, col + 1
    while i < N and j < N:
        if board[i][j] == 1:
            return False

        i += 1
        j += 1

    i, j = row - 1, col - 1
    while i >= 0 and j >= 0:
        if board[i][j] == 1:
            return False
        i -= 1
        j -= 1

    i, j = row + 1, col - 1
    while i < N and j >= 0:
        if board[i][j] == 1:
            return False
        i += 1
        j -= 1

    return True

def solveNQUtil(board):
    if not cols:
        return True
    col = list(cols)[0]
    for i in range(N):
        if isSafe(board, i, col):
            board[i][col] = 1
            cols.remove(col)
            if solveNQUtil(board) == True:
                return True
            cols.add(col)
            board[i][col] = 0
    return False

def solveNQ():
    board = []
    for i in range(N):
        temp = []
        for j in range(N):
            temp.append(0)
        board.append(temp)
    i, j = input("Enter i, j position of first queen : ").split()
    i, j = int(i), int(j)
    board[i][j] = 1
    cols.remove(j)
    if solveNQUtil(board) == False:
        print("Solution does not exist")
        return False
    printSolution(board)
    return True

solveNQ()




########################################################################


                       ##########ML############

###  UBER 

#Importing the required libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

#importing the dataset
df  = pd.read_csv("uber.csv")

df.columns #TO get number of columns in the dataset

df = df.drop(['Unnamed: 0', 'key'], axis= 1) #To drop unnamed column as it isn't required

df['dropoff_latitude'].fillna(value=df['dropoff_latitude'].mean(),inplace = True)
df['dropoff_longitude'].fillna(value=df['dropoff_longitude'].median(),inplace = True)

df.isnull().sum() 

df.dtypes

df.pickup_datetime = pd.to_datetime(df.pickup_datetime, errors='coerce') 

df.dtypes

df= df.assign(hour = df.pickup_datetime.dt.hour,
             day= df.pickup_datetime.dt.day,
             month = df.pickup_datetime.dt.month,
             year = df.pickup_datetime.dt.year,
             dayofweek = df.pickup_datetime.dt.dayofweek)

# drop the column 'pickup_daetime' using drop()
# 'axis = 1' drops the specified column
df = df.drop('pickup_datetime',axis=1)

df.head()

df.dtypes

df.plot(kind = "box",subplots = True,layout = (7,2),figsize=(15,20)) #Boxplot to check the outliers


#Using the InterQuartile Range to fill the values
def remove_outlier(df1 , col):
    Q1 = df1[col].quantile(0.25)
    Q3 = df1[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_whisker = Q1-1.5*IQR
    upper_whisker = Q3+1.5*IQR
    df[col] = np.clip(df1[col] , lower_whisker , upper_whisker)
    return df1

def treat_outliers_all(df1 , col_list):
    for c in col_list:
        df1 = remove_outlier(df , c)
    return df1

df = treat_outliers_all(df , df.iloc[: , 0::])

df.plot(kind = "box",subplots = True,layout = (7,2),figsize=(15,20)) #Boxplot shows that dataset is free from outliers

#pip install haversine
import haversine as hs  #Calculate the distance using Haversine to calculate the distance between to points. Can't use Eucladian as it is for flat surface.
travel_dist = []
for pos in range(len(df['pickup_longitude'])):
        long1,lati1,long2,lati2 = [df['pickup_longitude'][pos],df['pickup_latitude'][pos],df['dropoff_longitude'][pos],df['dropoff_latitude'][pos]]
        loc1=(lati1,long1)
        loc2=(lati2,long2)
        c = hs.haversine(loc1,loc2)
        travel_dist.append(c)
print(travel_dist)
df['dist_travel_km'] = travel_dist
df.head()

#Uber doesn't travel over 130 kms so minimize the distance 
df= df.loc[(df.dist_travel_km >= 1) | (df.dist_travel_km <= 130)]
print("Remaining observastions in the dataset:", df.shape)

#Finding inccorect latitude (Less than or greater than 90) and longitude (greater than or less than 180)
incorrect_coordinates = df.loc[(df.pickup_latitude > 90) |(df.pickup_latitude < -90) |
                                   (df.dropoff_latitude > 90) |(df.dropoff_latitude < -90) |
                                   (df.pickup_longitude > 180) |(df.pickup_longitude < -180) |
                                   (df.dropoff_longitude > 90) |(df.dropoff_longitude < -90)

df.drop(incorrect_coordinates, inplace = True, errors = 'ignore')

df.head()

df.isnull().sum()

sns.heatmap(df.isnull()) #Free for null values

corr = df.corr() #Function to find the correlation

corr

fig,axis = plt.subplots(figsize = (10,6))
sns.heatmap(df.corr(),annot = True) #Correlation Heatmap (Light values means highly correlated)

x = df[['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count','hour','day','month','year','dayofweek','dist_travel_km']]

y = df['fare_amount']


#Dividing Dataset into Trainig and Testing Datatset


from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.33)


#LINEAR REGRESSION

from sklearn.linear_model import LinearRegression
regression = LinearRegression()

regression.fit(X_train,y_train)

regression.intercept_ #To find the linear intercept

regression.coef_ #To find the linear coeeficient

prediction = regression.predict(X_test) #To predict the target values

print(prediction)

y_test

#METRICS EVALUATION USING RMS AND R2

from sklearn.metrics import r2_score 

r2_score(y_test,prediction)

from sklearn.metrics import mean_squared_error

MSE = mean_squared_error(y_test,prediction)

MSE 

RMSE = np.sqrt(MSE)

RMSE

#RANDOM FOREST REGRESSION

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=100) #Here n_estimators means number of trees you want to build before making the prediction

rf.fit(X_train,y_train)

y_pred = rf.predict(X_test)

y_pred

#METRICS EVALUATION FOR RANDOM FOREST

R2_Random = r2_score(y_test,y_pred)

R2_Random

MSE_Random = mean_squared_error(y_test,y_pred)

MSE_Random

RMSE_Random = np.sqrt(MSE_Random)

RMSE_Random


##########################################################################

##EMAIL SPAM CLASSIFICATION

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn import metrics

df = pd.read_csv('emails.csv')

df.isnull().sum()

df.dropna(inplace=True)

df.drop(["Email No."], axis=1, inplace=True)
X = df.drop(['Prediction'],axis = 1)
y = df['Prediction']

from sklearn.preprocessing import scale
X = scale(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=7)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

print("Prediction",y_pred)

print("KNN accuracy = ", metrics.accuracy_score(y_test,y_pred))

print('Confusion matrix', metrics.confusion_matrix(y_test,y_pred))

model = SVC(C = 1)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

metrics.confusion_matrix(y_true=y_test, y_pred=y_pred)

print('SVM accuracy = ',metrics.accuracy_score(y_test,y_pred))


################################################################################

##DIABETIES

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn import metrics

df = pd.read_csv("diabetes.csv")

df.columns

df.isnull().sum()

X = df.drop('Outcome', axis = 1)
y = df['Outcome']

from sklearn.preprocessing import scale
X = scale(X)
#spit into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=None)

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=7)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

print("Confusion matrix: ")
cs = metrics.confusion_matrix(y_test,y_pred)
print(cs)

print("Accuracy ",metrics.accuracy_score(y_test,y_pred))

total_misclassified = cs[0,1] + cs[1,0]
print(total_misclassified)
total_examples = cs[0,0]+cs[0,1]+cs[1,0]+cs[1,1]
print(total_examples)
print("Error rate", total_misclassified/total_examples)
print("Error rate ",1-metrics.accuracy_score(y_test,y_pred))

print("Precision score",metrics.precision_score(y_test,y_pred))

print("Recall score ", metrics.recall_score(y_test,y_pred))

print("Classification report ",metrics.classification_report(y_test,y_pred))


############################################################################

##


		

